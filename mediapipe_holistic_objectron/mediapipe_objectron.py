# -*- coding: utf-8 -*-
"""mediapipe_objectron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V7UxCaOuyeUWL2kwEc1RqgJrbtutzfPI
"""

!pip install mediapipe

from google.colab import files
import cv2
from google.colab.patches import cv2_imshow
import numpy as np

import mediapipe as mp
mp_objectron = mp.solutions.objectron
mp_drawing = mp.solutions.drawing_utils

"""Mediapipe Objectron provides pre-trained models for shoe, chair, cup and camera.

***
#Objectron Shoe Model

Upload any image that that has a person with visible upper body to the Colab. We take two examples image from the web: https://unsplash.com/photos/8dukMg99Hd8 and https://unsplash.com/photos/PqbL_mxmaUE
"""

import glob

# Read images with OpenCV.
shoe_images = {name: cv2.imread(name) for name in glob.glob("shoes/*.png")}

# Preview the images.
for name, image in shoe_images.items():
  print(name)   
  cv2_imshow(image)

with mp_objectron.Objectron(
    static_image_mode=True,
    max_num_objects=5,
    min_detection_confidence=0.5,
    model_name='Shoe') as objectron:
  # Run inference on shoe images.
  for name, image in shoe_images.items():
    # Convert the BGR image to RGB and process it with MediaPipe Objectron.
    results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Draw box landmarks.
    if not results.detected_objects:
      print(f'No box landmarks detected on {name}')
      continue
    print(f'Box landmarks of {name}:')
    annotated_image = image.copy()
    for detected_object in results.detected_objects:
      mp_drawing.draw_landmarks(
          annotated_image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)
      mp_drawing.draw_axis(annotated_image, detected_object.rotation, detected_object.translation)
    cv2_imshow(annotated_image)

"""***
#Objectron Chair Model

Upload any image that that has chairs to the Colab. We take one example image from the web: https://unsplash.com/photos/7T8vSHYXq4U
"""

import glob

# Read images with OpenCV.
chair_images = {name: cv2.imread(name) for name in glob.glob("chair/*.png")}

# Preview the images.
for name, image in chair_images.items():
  print(name)   
  cv2_imshow(image)

with mp_objectron.Objectron(
    static_image_mode=True,
    max_num_objects=5,
    min_detection_confidence=0.5,
    model_name='Chair') as objectron:
  # Run inference on chair images.
  for name, image in chair_images.items():
    # Convert the BGR image to RGB and process it with MediaPipe Objectron.
    results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Draw box landmarks.
    if not results.detected_objects:
      print(f'No box landmarks detected on {name}')
      continue
    print(f'Box landmarks of {name}:')
    annotated_image = image.copy()
    for detected_object in results.detected_objects:
      mp_drawing.draw_landmarks(
          annotated_image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)
      mp_drawing.draw_axis(annotated_image, detected_object.rotation, detected_object.translation)
    cv2_imshow(annotated_image)

"""***
#Objectron Cup Model

Upload any image that that has cups to the Colab. We take one example image from the web: https://unsplash.com/photos/WJ7gZ3cilBA
"""

import glob

# Read images with OpenCV.
cup_images = {name: cv2.imread(name) for name in glob.glob("cup/*.png")}

# Preview the images.
for name, image in cup_images.items():
  print(name)   
  cv2_imshow(image)

with mp_objectron.Objectron(
    static_image_mode=True,
    max_num_objects=5,
    min_detection_confidence=0.5,
    model_name='Cup') as objectron:
  # Run inference on cup images.
  for name, image in cup_images.items():
    # Convert the BGR image to RGB and process it with MediaPipe Objectron.
    results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Draw box landmarks.
    if not results.detected_objects:
      print(f'No box landmarks detected on {name}')
      continue
    print(f'Box landmarks of {name}:')
    annotated_image = image.copy()
    for detected_object in results.detected_objects:
      mp_drawing.draw_landmarks(
          annotated_image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)
      mp_drawing.draw_axis(annotated_image, detected_object.rotation, detected_object.translation)
    cv2_imshow(annotated_image)

"""***
#Objectron Camera Model

Upload any image that that has cups to the Colab. We take one example image from the web: https://unsplash.com/photos/XzL8YAWdirE
"""

import glob

# Read images with OpenCV
camera_images = {name: cv2.imread(name) for name in glob.glob("camera/*.png")}

# Preview the images.
for name, image in camera_images.items():
  print(name)   
  cv2_imshow(image)

with mp_objectron.Objectron(
    static_image_mode=True,
    max_num_objects=5,
    min_detection_confidence=0.5,
    model_name='Camera') as objectron:
  # Run inference on camera images.
  for name, image in camera_images.items():
    # Convert the BGR image to RGB and process it with MediaPipe Objectron.
    results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Draw box landmarks.
    if not results.detected_objects:
      print(f'No box landmarks detected on {name}')
      continue
    print(f'Box landmarks of {name}:')
    annotated_image = image.copy()
    for detected_object in results.detected_objects:
      mp_drawing.draw_landmarks(
          annotated_image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)
      mp_drawing.draw_axis(annotated_image, detected_object.rotation, detected_object.translation)
    cv2_imshow(annotated_image)

